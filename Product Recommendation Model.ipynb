{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Market Basket Analysis of Instacart Data\n",
    "## Convert from R to Python\n",
    "\n",
    "# Loading Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Loading Data\n",
    "products = pd.read_csv(\"Data/products.csv\")\n",
    "orders = pd.read_csv(\"Data/orders.csv\")\n",
    "prior = pd.read_csv(\"Data/order_products__prior.csv\")\n",
    "aisles = pd.read_csv(\"Data/aisles.csv\")\n",
    "departments = pd.read_csv(\"Data/departments.csv\")\n",
    "Ordertrain = pd.read_csv(\"Data/order_products__train.csv\")\n",
    "\n",
    "# Viewing Data\n",
    "print(orders.head(5))\n",
    "print(products.head(5))\n",
    "print(aisles.head(5))\n",
    "print(departments.head(5))\n",
    "print(prior.head(5))\n",
    "\n",
    "# Converting the data to the required formats for the orders, products, aisles and departments data set to factors and numeric values.\n",
    "\n",
    "# Final data set types of each of the data set is as below.\n",
    "print(pd.DataFrame({\"orders\": orders.dtypes}))\n",
    "print(pd.DataFrame({\"aisles\": aisles.dtypes}))\n",
    "print(pd.DataFrame({\"departments\": departments.dtypes}))\n",
    "print(pd.DataFrame({\"prior\": prior.dtypes}))\n",
    "print(pd.DataFrame({\"products\": products.dtypes}))\n",
    "\n",
    "# Merging the dataset of products, aisles and department data sets to view the product offerings.\n",
    "ProductsNAisles = pd.merge(products, aisles, on = \"aisle_id\")\n",
    "ProductsNAislesNDepartments = pd.merge(ProductsNAisles, departments, on = \"department_id\")\n",
    "print(ProductsNAislesNDepartments.head(5))\n",
    "print(\"After merging the data below is the results. The Merged products, Aisles and Departments data has\",ProductsNAislesNDepartments.shape[0],\"Rows and\",ProductsNAislesNDepartments.shape[1],\"Columns\")\n",
    "\n",
    "# Top 15 and Bottom 15 Aisle by Variety of Product Offering\n",
    "Number_of_Product_each_Aisle = ProductsNAislesNDepartments.groupby(\"aisle\")[\"product_id\"].count().reset_index(name=\"Number_of_Products\")\n",
    "Number_of_Product_each_Aisle = Number_of_Product_each_Aisle.sort_values(by=\"Number_of_Products\",ascending=False)\n",
    "\n",
    "Top_15 = Number_of_Product_each_Aisle.head(15)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(Top_15['aisle'], Top_15['Number_of_Products'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 15 Aisle by Variety of Product Offering\")\n",
    "plt.xlabel(\"Number of Products\")\n",
    "plt.ylabel(\"Aisle\")\n",
    "for i, v in enumerate(Top_15['Number_of_Products']):\n",
    "    plt.text(v, i, \" \"+str(round(v,0)), color='black', va=\"center\")\n",
    "plt.show()\n",
    "\n",
    "Bottom_15 = Number_of_Product_each_Aisle.tail(15)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(Bottom_15['aisle'], Bottom_15['Number_of_Products'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Bottom 15 Aisle by Variety of Product Offering\")\n",
    "plt.xlabel(\"Number of Products\")\n",
    "plt.ylabel(\"Aisle\")\n",
    "for i, v in enumerate(Bottom_15['Number_of_Products']):\n",
    "    plt.text(v, i, \" \"+str(round(v,0)), color='black', va=\"center\")\n",
    "plt.show()\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "## Pytorch Version Template\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('instacart_data.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "# ...\n",
    "\n",
    "# Prepare the data for training\n",
    "X = torch.tensor(data.drop('target', axis=1).values, dtype=torch.float32)\n",
    "y = torch.tensor(data['target'].values, dtype=torch.float32)\n",
    "dataset = torch.utils.data.TensorDataset(X, y)\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [80000, 10000, 10000])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define the model\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "model = MyModel(X.shape[1])\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = model(val_loader.dataset.tensors[0])\n",
    "        val_loss = criterion(y_val_pred, val_loader.dataset.tensors[1].unsqueeze(1))\n",
    "    print(f'Epoch {epoch+1}: Train loss = {loss:.4f}, Val loss = {val_loss:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(test_loader.dataset.tensors[0])\n",
    "    test_loss = criterion(y_test_pred, test_loader.dataset.tensors[1].unsqueeze(1))\n",
    "    y_test_pred = y_test_pred.numpy().flatten()\n",
    "    y_test_true = test_loader.dataset.tensors[1].numpy()\n",
    "    accuracy = ((y_test_pred > 0.5) == y_test_true).mean()\n",
    "print(f'Test loss = {test_loss:.4f}, Accuracy = {accuracy:.4f}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'my_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
